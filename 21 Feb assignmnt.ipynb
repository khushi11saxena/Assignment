{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is the process of extracting data from websites using automated software or tools. It is used to collect data from various websites for purposes such as data collection, content aggregation, and data analysis.\n",
    "\n",
    "\n",
    "Three areas where web scraping is commonly used to get data are:\n",
    "    \n",
    "1. E-commerce: Web scraping is used to collect product information, prices, and reviews from e-commerce websites. This data can be used for competitor analysis, price monitoring, and market research.\n",
    "    \n",
    "2. Social media: Web scraping is used to collect data from social media platforms like Twitter, Facebook, and LinkedIn. This data can be used for sentiment analysis, trend analysis, and social media monitoring.\n",
    "    \n",
    "3. Research: Web scraping is used in academic research to collect data from various websites, including government databases, news websites, and research papers. This data can be used for analysis and data visualization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods used for web scraping, including:\n",
    "\n",
    "1. HTML parsing: This method involves parsing the HTML code of a website to extract specific data. This can be done using libraries such as Beautiful Soup or lxml in Python.\n",
    "    \n",
    "2. Web API: Some websites offer Web APIs that allow developers to access data in a structured format. This method involves sending requests to the API and receiving data in a structured format such as JSON or XML.\n",
    "\n",
    "3. Headless browsing: This method involves using a headless browser to interact with a website and extract data. A headless browser is a browser that doesn't have a user interface, allowing it to be controlled programmatically.\n",
    "\n",
    "4. Machine learning-based approaches: Machine learning algorithms can be used to extract specific data from websites by training models on relevant data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for web scraping purposes. It is used to extract data from HTML and XML files. Beautiful Soup provides a simple and intuitive way to navigate, search, and modify the parse tree generated from the HTML source code.\n",
    "\n",
    "It is used because of several reasons:\n",
    "\n",
    "1.Ease of use\n",
    "\n",
    "2.Compatibility\n",
    "\n",
    "3.Integration with other python libraries.\n",
    "\n",
    "4.Robust Parsing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several reasons why Flask might be used in a web scraping project:\n",
    "    \n",
    "1. Data visualization: Flask can be used to build a web application that presents the scraped data in an easy-to-understand format, such as graphs or charts.\n",
    "    \n",
    "2. User interface: Flask can be used to build a user interface for the web scraping project, allowing users to interact with the data in a more intuitive way.\n",
    "    \n",
    "3. Automation: Flask can be used to automate the web scraping process, allowing for regular updates of the data.\n",
    "    \n",
    "4. Integration: Flask can be easily integrated with other Python libraries, allowing for more advanced data analysis or visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project two AWS services uses\n",
    "\n",
    "1. First one is Code Pipeline, which is used to connect github repo.\n",
    "2. Second one is Beanstalk, which is used to connect with code pipeline"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
